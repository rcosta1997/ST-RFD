{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random as rd\n",
    "import platform\n",
    "import adamod\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from utils.dataset import NCDFDatasets\n",
    "from utils.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load specific variables for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "data_path = '../../../data/dataset-chirps-1981-2019-seq5-ystep5.nc'\n",
    "dataset_type = 'chirps'\n",
    "input_size = 50\n",
    "step = 5\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.001\n",
    "param = {'encoder_layer_size': 3, 'decoder_layer_size': 3, 'kernel_size': 5, 'filter_size': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#util = Util('STConvS2S', version=version, dataset_type=dataset_type)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1000\n",
    "np.random.seed(seed)\n",
    "rd.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed):\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed = init_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 25\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "encoder_layer_size = param['encoder_layer_size']\n",
    "decoder_layer_size = param['decoder_layer_size']\n",
    "kernel_size = param['kernel_size']\n",
    "filter_size = param['filter_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (channel: 1, lat: 50, lon: 50, sample: 13960, time: 5)\n",
       "Coordinates:\n",
       "  * lat      (lat) int64 -39 -38 -37 -36 -35 -34 -33 -32 ... 3 4 5 6 7 8 9 10\n",
       "  * lon      (lon) int64 -84 -83 -82 -81 -80 -79 -78 ... -40 -39 -38 -37 -36 -35\n",
       "Dimensions without coordinates: channel, sample, time\n",
       "Data variables:\n",
       "    x        (sample, time, lat, lon, channel) float32 ...\n",
       "    y        (sample, time, lat, lon, channel) float32 ...\n",
       "Attributes:\n",
       "    description:  The variables have preciptation values and are separable in...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (channel: 1, lat: 50, lon: 50, sample: 13960, time: 5)\n",
       "Coordinates:\n",
       "  * lat      (lat) int64 -39 -38 -37 -36 -35 -34 -33 -32 ... 3 4 5 6 7 8 9 10\n",
       "  * lon      (lon) int64 -84 -83 -82 -81 -80 -79 -78 ... -40 -39 -38 -37 -36 -35\n",
       "Dimensions without coordinates: channel, sample, time\n",
       "Data variables:\n",
       "    x        (sample, time, lat, lon, channel) float32 ...\n",
       "    y        (sample, time, lat, lon, channel) float32 ...\n",
       "Attributes:\n",
       "    description:  The variables have preciptation values and are separable in..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = xr.open_dataset(data_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NCDFDatasets(dataset, val_split = validation_split, test_split = test_split)\n",
    "train_data = data.get_train()\n",
    "val_data = data.get_val()\n",
    "test_data = data.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X_train] Shape: torch.Size([8376, 1, 5, 50, 50])\n",
      "[y_train] Shape: torch.Size([8376, 1, 5, 50, 50])\n",
      "[X_val] Shape: torch.Size([2792, 1, 5, 50, 50])\n",
      "[y_val] Shape: torch.Size([2792, 1, 5, 50, 50])\n",
      "[X_test] Shape: torch.Size([2792, 1, 5, 50, 50])\n",
      "[y_test] Shape: torch.Size([2792, 1, 5, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "print('[X_train] Shape:', train_data.x.shape)\n",
    "print('[y_train] Shape:', train_data.y.shape)\n",
    "print('[X_val] Shape:', val_data.x.shape)\n",
    "print('[y_val] Shape:', val_data.y.shape)\n",
    "print('[X_test] Shape:', test_data.x.shape)\n",
    "print('[y_test] Shape:', test_data.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': batch_size,\n",
    "          'num_workers': 4, \n",
    "          'worker_init_fn': init_seed}\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, shuffle=True, **params)\n",
    "val_loader = DataLoader(dataset=val_data, shuffle=False, **params)\n",
    "test_loader = DataLoader(dataset=test_data, shuffle=False, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "class EncoderSTCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size, kernel_size, initial_filter_size, channels):\n",
    "        super(EncoderSTCNN, self).__init__()\n",
    "        self.padding = kernel_size // 2\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.relu_layers = nn.ModuleList()\n",
    "        self.batch_layers = nn.ModuleList()\n",
    "        self.dropout_layers = nn.ModuleList()\n",
    "        \n",
    "        spatial_kernel_size =  [1, kernel_size, kernel_size]\n",
    "        spatial_padding =  [0, self.padding, self.padding]\n",
    "        \n",
    "        out_channels = initial_filter_size\n",
    "        in_channels = channels\n",
    "        for i in range(layer_size):\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv3d(in_channels=in_channels, out_channels=out_channels, \n",
    "                          kernel_size=spatial_kernel_size, padding=spatial_padding, bias=False)\n",
    "            )\n",
    "            self.relu_layers.append(nn.ReLU())\n",
    "            self.batch_layers.append(nn.BatchNorm3d(out_channels))\n",
    "            self.dropout_layers.append(nn.Dropout(dropout_rate))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for conv, relu, batch, drop in zip(self.conv_layers, self.relu_layers, \n",
    "                                           self.batch_layers, self.dropout_layers):\n",
    "            x = conv(x)\n",
    "            x = batch(x)\n",
    "            x = relu(x)\n",
    "            x = drop(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSTCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size, kernel_size, initial_filter_size, channels):\n",
    "        super(DecoderSTCNN, self).__init__()\n",
    "        self.padding = kernel_size - 1\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.relu_layers = nn.ModuleList()\n",
    "        self.batch_layers = nn.ModuleList()\n",
    "        self.dropout_layers = nn.ModuleList()\n",
    "\n",
    "        temporal_kernel_size =  [kernel_size, 1, 1]\n",
    "        temporal_padding =  [self.padding, 0, 0]\n",
    "        \n",
    "        out_channels = initial_filter_size\n",
    "        in_channels = channels\n",
    "        for i in range(layer_size):\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv3d(in_channels=in_channels, out_channels=out_channels, \n",
    "                          kernel_size=temporal_kernel_size, padding=temporal_padding, bias=False)\n",
    "            )\n",
    "            self.relu_layers.append(nn.ReLU())\n",
    "            self.batch_layers.append(nn.BatchNorm3d(out_channels))\n",
    "            self.dropout_layers.append(nn.Dropout(dropout_rate))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        padding_final = [kernel_size // 2, 0, 0]\n",
    "        self.conv_final = nn.Conv3d(in_channels=in_channels, out_channels=1, \n",
    "              kernel_size=temporal_kernel_size, padding=padding_final, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for conv, relu, batch, drop in zip(self.conv_layers, self.relu_layers, \n",
    "                                           self.batch_layers, self.dropout_layers):\n",
    "            x = conv(x)[:,:,:-self.padding,:,:]\n",
    "            x = batch(x)\n",
    "            x = relu(x)\n",
    "            x = drop(x)\n",
    "            \n",
    "        out = self.conv_final(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STConvS2S(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_layer_size, decoder_layer_size, kernel_size, \n",
    "                 filter_size, channels):\n",
    "        super(STConvS2S, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderSTCNN(layer_size=encoder_layer_size, kernel_size=kernel_size, \n",
    "                                  initial_filter_size=filter_size, channels=channels)\n",
    "        self.decoder = DecoderSTCNN(layer_size=decoder_layer_size, kernel_size=kernel_size, \n",
    "                                  initial_filter_size=filter_size, channels=filter_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return self.decoder(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "model = STConvS2S(encoder_layer_size, decoder_layer_size, kernel_size, \n",
    "                 filter_size, channels=train_data.x.shape[1]).to(device)\n",
    "criterion = torch.nn.L1Loss()\n",
    "opt_params = {'lr': 0.001, \n",
    "              'alpha': 0.9, \n",
    "              'eps': 1e-6}\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), **opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'ntpath' from 'c:\\\\users\\\\mario\\\\anaconda3\\\\envs\\\\pytorch\\\\lib\\\\ntpath.py'>\n",
      "../models/STConvS2S_Mish_Adamod_m04d07-h20m07s52.pth.tar\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('../../../models/STConvS2S_Mish_Adamod' + '_' + datetime.now().strftime('m%md%d-h%Hm%Ms%S') + '.pth.tar')\n",
    "trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, 100, device, False, model_filename, 5)\n",
    "model_path = trainer.get_model_path()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 0, Epoch Loss: 2.326573\n",
      "Val Avg. Loss: 2.407170\n",
      "=> Saving a new best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001A0259489D8>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\mario\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\users\\mario\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"c:\\users\\mario\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"c:\\users\\mario\\anaconda3\\envs\\pytorch\\lib\\multiprocessing\\popen_spawn_win32.py\", line 104, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-be0b857adfcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Ambiente de Trabalho\\Thesis\\ST_Deep_Forecaster\\utils\\trainer.py\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train - Epoch %d, Epoch Loss: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Ambiente de Trabalho\\Thesis\\ST_Deep_Forecaster\\utils\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_losses)\u001b[0m\n\u001b[0;32m     46\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                         \u001b[0mepoch_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                 \u001b[0mavg_epoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_train_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_epoch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = trainer.train_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = np.arange(1,len(val_losses))\n",
    "plt.figure(figsize=(15,10)) \n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model, criterion, test_loader, device)\n",
    "test_loss = evaluator.evaluate()\n",
    "loss_type = type(criterion).__name__\n",
    "print(f'STConvS2S {loss_type}: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
