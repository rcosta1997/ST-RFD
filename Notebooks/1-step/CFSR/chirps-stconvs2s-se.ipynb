{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random as rd\n",
    "import platform\n",
    "import adamod\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from utils.dataset import NCDFDatasets\n",
    "from utils.trainer import Trainer\n",
    "from utils.trainer import Tester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load specific variables for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "data_path = '../../../data/dataset-ucar-1979-2015-seq5-ystep5.nc'\n",
    "dataset_type = 'chirps'\n",
    "input_size = 50\n",
    "step = 5\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.001\n",
    "param = {'encoder_layer_size': 3, 'decoder_layer_size': 3, 'kernel_size': 5, 'filter_size': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#util = Util('STConvS2S', version=version, dataset_type=dataset_type)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1000\n",
    "np.random.seed(seed)\n",
    "rd.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_seed(seed):\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seed = init_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 25\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "encoder_layer_size = param['encoder_layer_size']\n",
    "decoder_layer_size = param['decoder_layer_size']\n",
    "kernel_size = param['kernel_size']\n",
    "filter_size = param['filter_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (channel: 1, lat: 32, lon: 32, sample: 54047, time: 5)\n",
       "Coordinates:\n",
       "  * lat      (lat) int32 -54 -52 -50 -48 -46 -44 -42 -40 ... -6 -4 -2 0 2 4 6 8\n",
       "  * lon      (lon) int32 278 280 282 284 286 288 290 ... 330 332 334 336 338 340\n",
       "Dimensions without coordinates: channel, sample, time\n",
       "Data variables:\n",
       "    x        (sample, time, lat, lon, channel) float32 ...\n",
       "    y        (sample, time, lat, lon, channel) float32 ...\n",
       "Attributes:\n",
       "    description:  The variables have air temperature values and are separable...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (channel: 1, lat: 32, lon: 32, sample: 54047, time: 5)\n",
       "Coordinates:\n",
       "  * lat      (lat) int32 -54 -52 -50 -48 -46 -44 -42 -40 ... -6 -4 -2 0 2 4 6 8\n",
       "  * lon      (lon) int32 278 280 282 284 286 288 290 ... 330 332 334 336 338 340\n",
       "Dimensions without coordinates: channel, sample, time\n",
       "Data variables:\n",
       "    x        (sample, time, lat, lon, channel) float32 ...\n",
       "    y        (sample, time, lat, lon, channel) float32 ...\n",
       "Attributes:\n",
       "    description:  The variables have air temperature values and are separable..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = xr.open_dataset(data_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NCDFDatasets(dataset, val_split = validation_split, test_split = test_split)\n",
    "train_data = data.get_train()\n",
    "val_data = data.get_val()\n",
    "test_data = data.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X_train] Shape: torch.Size([32429, 1, 5, 32, 32])\n",
      "[y_train] Shape: torch.Size([32429, 1, 5, 32, 32])\n",
      "[X_val] Shape: torch.Size([10809, 1, 5, 32, 32])\n",
      "[y_val] Shape: torch.Size([10809, 1, 5, 32, 32])\n",
      "[X_test] Shape: torch.Size([10809, 1, 5, 32, 32])\n",
      "[y_test] Shape: torch.Size([10809, 1, 5, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print('[X_train] Shape:', train_data.x.shape)\n",
    "print('[y_train] Shape:', train_data.y.shape)\n",
    "print('[X_val] Shape:', val_data.x.shape)\n",
    "print('[y_val] Shape:', val_data.y.shape)\n",
    "print('[X_test] Shape:', test_data.x.shape)\n",
    "print('[y_test] Shape:', test_data.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': batch_size,\n",
    "          'num_workers': 4, \n",
    "          'worker_init_fn': init_seed}\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, shuffle=True, **params)\n",
    "val_loader = DataLoader(dataset=val_data, shuffle=False, **params)\n",
    "test_loader = DataLoader(dataset=test_data, shuffle=False, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, out_channels, ratio):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        out_channels_reduced = out_channels // ratio\n",
    "        self.fc1 = nn.Linear(out_channels, out_channels_reduced, bias=True)\n",
    "        self.fc2 = nn.Linear(out_channels_reduced, out_channels, bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, num_channels, _, _, _ = x.size()\n",
    "        # Average along each channel\n",
    "        squeeze_tensor = self.avg_pool(x)\n",
    "\n",
    "        # channel excitation\n",
    "        fc_out_1 = self.relu(self.fc1(squeeze_tensor.view(batch_size, num_channels)))\n",
    "        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n",
    "\n",
    "        output_tensor = torch.mul(x, fc_out_2.view(batch_size, num_channels, 1, 1, 1))\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n",
    "        return x *( torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "class EncoderSTCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size, kernel_size, initial_filter_size, channels):\n",
    "        super(EncoderSTCNN, self).__init__()\n",
    "        self.padding = kernel_size // 2\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.mish_layers = nn.ModuleList()\n",
    "        self.batch_layers = nn.ModuleList()\n",
    "        self.se_layers = nn.ModuleList()\n",
    "        \n",
    "        spatial_kernel_size =  [1, kernel_size, kernel_size]\n",
    "        spatial_padding =  [0, self.padding, self.padding]\n",
    "        \n",
    "        out_channels = initial_filter_size\n",
    "        in_channels = channels\n",
    "        ratio = 2\n",
    "        for i in range(layer_size):\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv3d(in_channels=in_channels, out_channels=out_channels, \n",
    "                          kernel_size=spatial_kernel_size, padding=spatial_padding, bias=False)\n",
    "            )\n",
    "            self.mish_layers.append(Mish())\n",
    "            self.batch_layers.append(nn.BatchNorm3d(out_channels))\n",
    "            self.se_layers.append(SELayer(out_channels, ratio))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for conv, mish, batch, se in zip(self.conv_layers, self.mish_layers, \n",
    "                                           self.batch_layers, self.se_layers):\n",
    "            x = conv(x)\n",
    "            x = batch(x)\n",
    "            x = mish(x)\n",
    "            x = se(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSTCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size, kernel_size, initial_filter_size, channels):\n",
    "        super(DecoderSTCNN, self).__init__()\n",
    "        self.padding = kernel_size - 1\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.mish_layers = nn.ModuleList()\n",
    "        self.batch_layers = nn.ModuleList()\n",
    "        self.se_layers = nn.ModuleList()\n",
    "\n",
    "        temporal_kernel_size =  [kernel_size, 1, 1]\n",
    "        temporal_padding =  [self.padding, 0, 0]\n",
    "        \n",
    "        out_channels = initial_filter_size\n",
    "        in_channels = channels\n",
    "        ratio = 2\n",
    "        for i in range(layer_size):\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv3d(in_channels=in_channels, out_channels=out_channels, \n",
    "                          kernel_size=temporal_kernel_size, padding=temporal_padding, bias=False)\n",
    "            )\n",
    "            self.mish_layers.append(Mish())\n",
    "            self.batch_layers.append(nn.BatchNorm3d(out_channels))\n",
    "            self.se_layers.append(SELayer(out_channels, ratio))\n",
    "            in_channels = out_channels\n",
    "\n",
    "        padding_final = [kernel_size // 2, 0, 0]\n",
    "        self.conv_final = nn.Conv3d(in_channels=in_channels, out_channels=1, \n",
    "              kernel_size=temporal_kernel_size, padding=padding_final, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ratio=2\n",
    "        for conv, mish, batch, se in zip(self.conv_layers, self.mish_layers, \n",
    "                                           self.batch_layers, self.se_layers):\n",
    "            x = conv(x)[:,:,:-self.padding,:,:]\n",
    "            x = batch(x)\n",
    "            x = mish(x)\n",
    "            x = se(x)\n",
    "            \n",
    "        out = self.conv_final(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STConvS2S(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder_layer_size, decoder_layer_size, kernel_size, \n",
    "                 filter_size, channels):\n",
    "        super(STConvS2S, self).__init__()\n",
    "        \n",
    "        self.encoder = EncoderSTCNN(layer_size=encoder_layer_size, kernel_size=kernel_size, \n",
    "                                  initial_filter_size=filter_size, channels=channels)\n",
    "        self.decoder = DecoderSTCNN(layer_size=decoder_layer_size, kernel_size=kernel_size, \n",
    "                                  initial_filter_size=filter_size, channels=filter_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return self.decoder(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "model = STConvS2S(encoder_layer_size, decoder_layer_size, kernel_size, \n",
    "                 filter_size, channels=train_data.x.shape[1]).to(device)\n",
    "criterion = RMSELoss()\n",
    "opt_params = {'lr': 0.001, \n",
    "              'beta3': 0.999}\n",
    "optimizer = adamod.AdaMod(model.parameters(), **opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('../../../models/CFSR/1_step/STConvS2S_SE' + '_' + datetime.now().strftime('m%md%d-h%Hm%Ms%S') + '.pth.tar')\n",
    "trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, 100, device, True, model_path, False, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 0, Epoch Loss: 3.752273\n",
      "Val Avg. Loss: 1.598353\n",
      "=> Saving a new best\n",
      "Train - Epoch 1, Epoch Loss: 1.587401\n",
      "Val Avg. Loss: 1.518664\n",
      "=> Saving a new best\n",
      "Train - Epoch 2, Epoch Loss: 1.534189\n",
      "Val Avg. Loss: 1.495657\n",
      "=> Saving a new best\n",
      "Train - Epoch 3, Epoch Loss: 1.495913\n",
      "Val Avg. Loss: 1.482676\n",
      "=> Saving a new best\n",
      "Train - Epoch 4, Epoch Loss: 1.468142\n",
      "Val Avg. Loss: 1.462295\n",
      "=> Saving a new best\n",
      "Train - Epoch 5, Epoch Loss: 1.449731\n",
      "Val Avg. Loss: 1.434751\n",
      "=> Saving a new best\n",
      "Train - Epoch 6, Epoch Loss: 1.437207\n",
      "Val Avg. Loss: 1.468767\n",
      "Train - Epoch 7, Epoch Loss: 1.425726\n",
      "Val Avg. Loss: 1.431463\n",
      "=> Saving a new best\n",
      "Train - Epoch 8, Epoch Loss: 1.412864\n",
      "Val Avg. Loss: 1.436066\n",
      "Train - Epoch 9, Epoch Loss: 1.401627\n",
      "Val Avg. Loss: 1.487032\n",
      "Train - Epoch 10, Epoch Loss: 1.392862\n",
      "Val Avg. Loss: 1.369839\n",
      "=> Saving a new best\n",
      "Train - Epoch 11, Epoch Loss: 1.385233\n",
      "Val Avg. Loss: 1.387720\n",
      "Train - Epoch 12, Epoch Loss: 1.377596\n",
      "Val Avg. Loss: 1.407148\n",
      "Train - Epoch 13, Epoch Loss: 1.372414\n",
      "Val Avg. Loss: 1.361856\n",
      "=> Saving a new best\n",
      "Train - Epoch 14, Epoch Loss: 1.366878\n",
      "Val Avg. Loss: 1.364911\n",
      "Train - Epoch 15, Epoch Loss: 1.362797\n",
      "Val Avg. Loss: 1.358379\n",
      "=> Saving a new best\n",
      "Train - Epoch 16, Epoch Loss: 1.357263\n",
      "Val Avg. Loss: 1.349067\n",
      "=> Saving a new best\n",
      "Train - Epoch 17, Epoch Loss: 1.353825\n",
      "Val Avg. Loss: 1.398068\n",
      "Train - Epoch 18, Epoch Loss: 1.348112\n",
      "Val Avg. Loss: 1.387345\n",
      "Train - Epoch 19, Epoch Loss: 1.344714\n",
      "Val Avg. Loss: 1.338218\n",
      "=> Saving a new best\n",
      "Train - Epoch 20, Epoch Loss: 1.341043\n",
      "Val Avg. Loss: 1.384380\n",
      "Train - Epoch 21, Epoch Loss: 1.336518\n",
      "Val Avg. Loss: 1.346120\n",
      "Train - Epoch 22, Epoch Loss: 1.335913\n",
      "Val Avg. Loss: 1.350664\n",
      "Train - Epoch 23, Epoch Loss: 1.332005\n",
      "Val Avg. Loss: 1.361060\n",
      "Train - Epoch 24, Epoch Loss: 1.328446\n",
      "Val Avg. Loss: 1.327269\n",
      "=> Saving a new best\n",
      "Train - Epoch 25, Epoch Loss: 1.325695\n",
      "Val Avg. Loss: 1.351337\n",
      "Train - Epoch 26, Epoch Loss: 1.321878\n",
      "Val Avg. Loss: 1.312101\n",
      "=> Saving a new best\n",
      "Train - Epoch 27, Epoch Loss: 1.319258\n",
      "Val Avg. Loss: 1.307269\n",
      "=> Saving a new best\n",
      "Train - Epoch 28, Epoch Loss: 1.317660\n",
      "Val Avg. Loss: 1.331434\n",
      "Train - Epoch 29, Epoch Loss: 1.316127\n",
      "Val Avg. Loss: 1.351322\n",
      "Train - Epoch 30, Epoch Loss: 1.314072\n",
      "Val Avg. Loss: 1.314536\n",
      "Train - Epoch 31, Epoch Loss: 1.311890\n",
      "Val Avg. Loss: 1.330981\n",
      "Train - Epoch 32, Epoch Loss: 1.310648\n",
      "Val Avg. Loss: 1.299780\n",
      "=> Saving a new best\n",
      "Train - Epoch 33, Epoch Loss: 1.308746\n",
      "Val Avg. Loss: 1.313760\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-be0b857adfcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Ambiente de Trabalho\\Thesis\\ST_Deep_Forecaster\\utils\\trainer.py\u001b[0m in \u001b[0;36mtrain_evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train - Epoch %d, Epoch Loss: %f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Ambiente de Trabalho\\Thesis\\ST_Deep_Forecaster\\utils\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_losses)\u001b[0m\n\u001b[0;32m     48\u001b[0m                         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                         \u001b[0mepoch_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                 \u001b[0mavg_epoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch_train_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_epoch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = trainer.train_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8a5b39a353e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_losses' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = np.arange(1,len(val_losses))\n",
    "plt.figure(figsize=(15,10)) \n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STConvS2S_SE RMSELoss: 1.2864\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, epoch, loss = trainer.load_model()\n",
    "tester = Tester(model, test_loader, criterion, optimizer, device, True, False)\n",
    "test_loss = tester.test()\n",
    "loss_type = type(criterion).__name__\n",
    "print(f'STConvS2S_SE {loss_type}: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
