{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1596462231864,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "IMHzItUioacc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5154,
     "status": "ok",
     "timestamp": 1596462236130,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "9od8RI0ooacl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random as rd\n",
    "import platform\n",
    "import adamod\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dataset import NCDFDatasets\n",
    "from utils.trainer import Tester\n",
    "from utils.trainer import Trainer\n",
    "from datetime import datetime\n",
    "from evonorm import EvoNorm3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4999,
     "status": "ok",
     "timestamp": 1596462236136,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "BmBWpLYioact",
    "outputId": "3cdba572-557b-4fc7-e35e-f8e7d5bf7b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4872,
     "status": "ok",
     "timestamp": 1596462236138,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "m9xBSYyPoac0"
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "validation_split = 0.2\n",
    "test_split = 0.2\n",
    "dropout_rate = 0.2\n",
    "hidden_size = 32*32\n",
    "mogrify_rounds = 5\n",
    "param = {'encoder_layer_size': 3, 'decoder_layer_size': 3, 'kernel_size': 5, 'filter_size': 32}\n",
    "weights = [0.9, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3378,
     "status": "ok",
     "timestamp": 1596462236138,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "vqedmBAzSsUQ"
   },
   "outputs": [],
   "source": [
    "seed = 1000\n",
    "np.random.seed(seed)\n",
    "rd.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def init_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "init_seed = init_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2185,
     "status": "ok",
     "timestamp": 1596462238539,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "EzsjPW-1oac4",
    "outputId": "1af582d4-ef0c-4cc8-cd1a-80e2fa8496c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (channel: 1, lat: 32, lon: 32, sample: 54047, time: 5)\n",
      "Coordinates:\n",
      "  * lat      (lat) int32 -54 -52 -50 -48 -46 -44 -42 -40 ... -6 -4 -2 0 2 4 6 8\n",
      "  * lon      (lon) int32 278 280 282 284 286 288 290 ... 330 332 334 336 338 340\n",
      "Dimensions without coordinates: channel, sample, time\n",
      "Data variables:\n",
      "    x        (sample, time, lat, lon, channel) float32 ...\n",
      "    y        (sample, time, lat, lon, channel) float32 ...\n",
      "Attributes:\n",
      "    description:  The variables have air temperature values and are separable...\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "data_path = '/content/drive/My Drive/Colab Notebooks/dataset-ucar-1979-2015-seq5-ystep5.nc'\n",
    "dataset = xr.open_dataset(data_path)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43239,
     "status": "ok",
     "timestamp": 1596462280758,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "Sjjdd5E7oac_"
   },
   "outputs": [],
   "source": [
    "#In these experiments y has dimensions [batch, channel, lat, lon] as opposed to [batch, channel, time, lat, lon] to\n",
    "#avoid dimension conflict with conv kernels\n",
    "data = NCDFDatasets(dataset, val_split = 0.2, test_split = 0.2,  data_type='Reconstruction')\n",
    "train_data = data.get_train()\n",
    "val_data = data.get_val()\n",
    "test_data = data.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 42991,
     "status": "ok",
     "timestamp": 1596462280764,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "X8EXuVkWoadD",
    "outputId": "5ca23074-b07e-4f4e-9070-faa241c96143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Train-----\n",
      "X :  torch.Size([32429, 1, 10, 32, 32])\n",
      "Y :  torch.Size([32429, 1, 10, 32, 32])\n",
      "Removed :  torch.Size([32429])\n",
      "-----Val-----\n",
      "X :  torch.Size([10809, 1, 10, 32, 32])\n",
      "Y :  torch.Size([10809, 1, 10, 32, 32])\n",
      "Removed :  torch.Size([10809])\n",
      "-----Test-----\n",
      "X :  torch.Size([10809, 1, 10, 32, 32])\n",
      "Y :  torch.Size([10809, 1, 10, 32, 32])\n",
      "Removed :  torch.Size([10809])\n"
     ]
    }
   ],
   "source": [
    "print(\"-----Train-----\")\n",
    "print(\"X : \", train_data.x.shape)\n",
    "print(\"Y : \", train_data.y.shape)\n",
    "print(\"Removed : \", train_data.removed.shape)\n",
    "print(\"-----Val-----\")\n",
    "print(\"X : \", val_data.x.shape)\n",
    "print(\"Y : \", val_data.y.shape)\n",
    "print(\"Removed : \", val_data.removed.shape)\n",
    "print(\"-----Test-----\")\n",
    "print(\"X : \", test_data.x.shape)\n",
    "print(\"Y : \", test_data.y.shape)\n",
    "print(\"Removed : \", test_data.removed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41446,
     "status": "ok",
     "timestamp": 1596462280765,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "MUMtg4RgoadM"
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': batch_size,\n",
    "          'num_workers': 4,\n",
    "          'worker_init_fn': init_seed}\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, shuffle=True, **params)\n",
    "val_loader = DataLoader(dataset=val_data, shuffle=False, **params)\n",
    "test_loader = DataLoader(dataset=test_data, shuffle=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41206,
     "status": "ok",
     "timestamp": 1596462280767,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "DX1dGHuNoadR"
   },
   "outputs": [],
   "source": [
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #inlining this saves 1 second per epoch (V100 GPU) vs having a temp x and then returning x(!)\n",
    "        return x *( torch.tanh(F.softplus(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39819,
     "status": "ok",
     "timestamp": 1596462280767,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "bXrfwg9eoadU"
   },
   "outputs": [],
   "source": [
    "class CustomConv3d(torch.nn.Conv3d):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1,\n",
    "                 bias=False, padding_mode='zeros', weight=None):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride=stride,\n",
    "                 padding=padding, dilation=dilation,\n",
    "                 bias=bias, padding_mode=padding_mode)\n",
    "        \n",
    "    def forward(self,input, weight=None):\n",
    "        if (weight is not None):\n",
    "            return F.conv3d(input, weight.permute(1,0,2,3,4), self.bias, self.stride,\n",
    "                        self.padding, self.dilation)\n",
    "        else:\n",
    "            return F.conv3d(input, self.weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1411,
     "status": "ok",
     "timestamp": 1596462282185,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "GQd_Q09foadZ"
   },
   "outputs": [],
   "source": [
    "class EncoderCNN(torch.nn.Module):\n",
    "    def __init__(self, layer_size, kernel_size, initial_out_channels, initial_in_channels, device):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.layer_size = layer_size\n",
    "        self.conv_layers = torch.nn.ModuleList()\n",
    "        #self.mish_layers = torch.nn.ModuleList()\n",
    "        self.bn_layers = torch.nn.ModuleList()\n",
    "        self.decode_bn_layers = torch.nn.ModuleList()\n",
    "        #self.dropout_layers = torch.nn.ModuleList()\n",
    "        \n",
    "        self.kernel_size = [1, kernel_size, kernel_size]\n",
    "        self.padding = [0, kernel_size // 2, kernel_size // 2]\n",
    "        \n",
    "        in_channels = initial_in_channels\n",
    "        out_channels = initial_out_channels\n",
    "        for i in range(self.layer_size):\n",
    "            self.conv_layers.append(CustomConv3d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                                padding = self.padding, kernel_size = self.kernel_size))\n",
    "            #self.mish_layers.append(Mish())\n",
    "            self.bn_layers.append(EvoNorm3D(out_channels, version = 'B0_3D'))\n",
    "            self.decode_bn_layers.append(EvoNorm3D(out_channels, version = 'B0_3D'))\n",
    "            #self.dropout_layers.append(torch.nn.Dropout(dropout_rate))\n",
    "            in_channels = out_channels\n",
    "        self.conv_reduce = CustomConv3d(in_channels = in_channels, out_channels = 1,\n",
    "                                                kernel_size = 1)\n",
    "            \n",
    "            \n",
    "    def forward(self, x, decode=False):#, x_rev=None):\n",
    "        if (decode):\n",
    "            x = self.conv_reduce(x, self.conv_reduce.weight)\n",
    "            #if (x_rev is not None):\n",
    "              #x_rev = self.conv_reduce(x_rev, self.conv_reduce.weight)\n",
    "              #x = (x + x_rev) / 2\n",
    "            for i in range(self.layer_size-1, -1, -1):\n",
    "                x = self.decode_bn_layers[i](x)\n",
    "                #x = self.dropout_layers[i](x)\n",
    "                x = self.conv_layers[i](x, self.conv_layers[i].weight)\n",
    "        else:\n",
    "            for i in range(self.layer_size):\n",
    "                x = self.conv_layers[i](x)\n",
    "                x = self.bn_layers[i](x)\n",
    "                #x = self.dropout_layers[i](x)\n",
    "            x = self.conv_reduce(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1596462282186,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "XI5UEKWSoadf"
   },
   "outputs": [],
   "source": [
    "class STModel(torch.nn.Module):\n",
    "    def __init__(self, encoder_layer_size, kernel_size, out_channels, in_channels, input_width, input_height, hidden_size\n",
    "                 , device):\n",
    "        super(STModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.encoder_fwd = EncoderCNN(layer_size = encoder_layer_size, kernel_size = kernel_size,\n",
    "                                initial_out_channels = out_channels,\n",
    "                                initial_in_channels = in_channels, device=device)\n",
    "        self.encoder_bckwd = EncoderCNN(layer_size = encoder_layer_size, kernel_size = kernel_size,\n",
    "                                initial_out_channels = out_channels,\n",
    "                                initial_in_channels = in_channels, device=device)\n",
    "        self.recurrent_forward = torch.nn.LSTMCell(input_width*input_height, hidden_size);\n",
    "        self.recurrent_backward = torch.nn.LSTMCell(input_width*input_height, hidden_size);\n",
    "       \n",
    "        \n",
    "    def forward(self, x, states_fwd, states_bckwd, removed):\n",
    "        batch, channel, time, lat, lon = x.size()\n",
    "        x_rev = torch.flip(x, [2])\n",
    "        x_fwd = self.encoder_fwd(x)\n",
    "        x_bckwd = self.encoder_bckwd(x_rev)\n",
    "        \n",
    "        x_fwd = x_fwd.squeeze().view(batch, time, -1)\n",
    "        x_bckwd = x_bckwd.squeeze().view(batch, time, -1)\n",
    "\n",
    "\n",
    "        h_fwd = states_fwd[0]\n",
    "        c_fwd = states_fwd[1]\n",
    "        h_bckwd = states_bckwd[0]\n",
    "        c_bckwd = states_bckwd[1]\n",
    "        \n",
    "        outputs_fwd = torch.zeros(batch, time, lat*lon, device=self.device)\n",
    "        outputs_bckwd = torch.zeros(batch, time, lat*lon, device=self.device)\n",
    "\n",
    "        for i in range(time):\n",
    "            h_fwd, c_fwd = self.recurrent_forward(x_fwd[:,i,:],(h_fwd,c_fwd))\n",
    "            outputs_fwd[:,i,:] = h_fwd\n",
    "            \n",
    "            h_bckwd, c_bckwd = self.recurrent_backward(x_bckwd[:,i,:], (h_bckwd,c_bckwd))\n",
    "            outputs_bckwd[:,i,:] = h_bckwd\n",
    "\n",
    "\n",
    "        x_fwd = outputs_fwd.contiguous().view(batch, channel, time, lat, lon)\n",
    "        x_bckwd = outputs_bckwd.contiguous().view(batch, channel, time, lat, lon)\n",
    "\n",
    "        x_fwd = self.encoder_fwd(x_fwd, decode=True)\n",
    "        x_bckwd = self.encoder_bckwd(x_bckwd, decode=True)\n",
    "\n",
    "        x_bckwd = torch.flip(x_bckwd, [2])\n",
    "        x = (x_fwd + x_bckwd) / 2\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1404,
     "status": "ok",
     "timestamp": 1596462282187,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "sYLu5bLFoadj"
   },
   "outputs": [],
   "source": [
    "class WeightedRMSELoss(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    '''def forward(self,y,yhat, removed):\n",
    "        #y : 25 x ch x time x lat x lon\n",
    "        #removed : 25\n",
    "        batch, ch, time, lat, lon = yhat.shape\n",
    "        cumulative_loss = 0\n",
    "        for i in range(batch):\n",
    "            cumulative_loss += self.mse(y[i,:,removed[i],:,:],  yhat[i,:,removed[i],:,:])\n",
    "        return torch.sqrt((cumulative_loss / (batch))+ self.eps)'''\n",
    "    def forward(self,yhat,y, removed):\n",
    "        #y : 25 x ch x time x lat x lon\n",
    "        #removed : 25\n",
    "        batch, ch, time, lat, lon = yhat.shape\n",
    "        cumulative_loss = 0\n",
    "        for i in range(batch):\n",
    "            for j in range(time):\n",
    "                weight = weights[0] if removed[i] == j else (weights[1]/(time-1))\n",
    "                cumulative_loss += self.mse(yhat[i,:,j,:,:], y[i,:,j,:,:]) * weight\n",
    "        return torch.sqrt((cumulative_loss / (batch))+ self.eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9072,
     "status": "ok",
     "timestamp": 1596462289864,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "HQgTWl0Koadn",
    "outputId": "85ddfff8-ac0b-4bc6-c115-9921b1b94b60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STModel(\n",
       "  (encoder_fwd): EncoderCNN(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): CustomConv3d(1, 32, kernel_size=[1, 5, 5], stride=(1, 1, 1), padding=[0, 2, 2], bias=False)\n",
       "      (1): CustomConv3d(32, 32, kernel_size=[1, 5, 5], stride=(1, 1, 1), padding=[0, 2, 2], bias=False)\n",
       "      (2): CustomConv3d(32, 32, kernel_size=[1, 5, 5], stride=(1, 1, 1), padding=[0, 2, 2], bias=False)\n",
       "    )\n",
       "    (bn_layers): ModuleList(\n",
       "      (0): EvoNorm3D()\n",
       "      (1): EvoNorm3D()\n",
       "      (2): EvoNorm3D()\n",
       "    )\n",
       "    (decode_bn_layers): ModuleList(\n",
       "      (0): EvoNorm3D()\n",
       "      (1): EvoNorm3D()\n",
       "      (2): EvoNorm3D()\n",
       "    )\n",
       "    (conv_reduce): CustomConv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (encoder_bckwd): EncoderCNN(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): CustomConv3d(1, 32, kernel_size=[1, 5, 5], stride=(1, 1, 1), padding=[0, 2, 2], bias=False)\n",
       "      (1): CustomConv3d(32, 32, kernel_size=[1, 5, 5], stride=(1, 1, 1), padding=[0, 2, 2], bias=False)\n",
       "      (2): CustomConv3d(32, 32, kernel_size=[1, 5, 5], stride=(1, 1, 1), padding=[0, 2, 2], bias=False)\n",
       "    )\n",
       "    (bn_layers): ModuleList(\n",
       "      (0): EvoNorm3D()\n",
       "      (1): EvoNorm3D()\n",
       "      (2): EvoNorm3D()\n",
       "    )\n",
       "    (decode_bn_layers): ModuleList(\n",
       "      (0): EvoNorm3D()\n",
       "      (1): EvoNorm3D()\n",
       "      (2): EvoNorm3D()\n",
       "    )\n",
       "    (conv_reduce): CustomConv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  )\n",
       "  (recurrent_forward): LSTMCell(1024, 1024)\n",
       "  (recurrent_backward): LSTMCell(1024, 1024)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = STModel(encoder_layer_size = param['encoder_layer_size'], kernel_size = param['kernel_size'], out_channels = param['filter_size'],\n",
    "                in_channels = train_data.x.shape[1], input_width = train_data.x.shape[3], \n",
    "                input_height = train_data.x.shape[4], hidden_size = hidden_size, device=device).to(device)\n",
    "criterion = WeightedRMSELoss()\n",
    "#optimizer_params = {'lr': 0.001}\n",
    "#optimizer = torch.optim.Adam(net.parameters(), **optimizer_params)\n",
    "opt_params = {'lr': 0.001, \n",
    "              'beta3': 0.999}\n",
    "optimizer = adamod.AdaMod(model.parameters(), **opt_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9070,
     "status": "ok",
     "timestamp": 1596462289866,
     "user": {
      "displayName": "Mario Cardoso",
      "photoUrl": "",
      "userId": "08606065989027222991"
     },
     "user_tz": 0
    },
    "id": "-aDNXZEfoads"
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join('ST-RFD-EvoNormB03D' + '_' + datetime.now().strftime('m%md%d-h%Hm%Ms%S') + '.pth.tar')\n",
    "trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, 100, device, model_path, recurrent_model= True, is_reconstruction=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "I7Mbaw0moadx",
    "outputId": "ce8d776e-0153-4c4a-84f5-be942c5dd755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 0, Epoch Loss: 2.270311\n",
      "Val Avg. Loss: 1.957585\n",
      "=> Saving a new best\n",
      "Train - Epoch 1, Epoch Loss: 1.586620\n",
      "Val Avg. Loss: 1.808128\n",
      "=> Saving a new best\n",
      "Train - Epoch 2, Epoch Loss: 1.470577\n",
      "Val Avg. Loss: 1.512345\n",
      "=> Saving a new best\n",
      "Train - Epoch 3, Epoch Loss: 1.385641\n",
      "Val Avg. Loss: 1.354613\n",
      "=> Saving a new best\n",
      "Train - Epoch 4, Epoch Loss: 1.310584\n",
      "Val Avg. Loss: 1.321224\n",
      "=> Saving a new best\n",
      "Train - Epoch 5, Epoch Loss: 1.226162\n",
      "Val Avg. Loss: 1.402413\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = trainer.train_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2512398,
     "status": "ok",
     "timestamp": 1594681538329,
     "user": {
      "displayName": "Mário Cardoso",
      "photoUrl": "",
      "userId": "07198817090508096649"
     },
     "user_tz": 0
    },
    "id": "vvt1Hujfoad1",
    "outputId": "de052884-9c0c-49bb-8064-84b6eedcd41c"
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(1,len(val_losses))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"RMSE Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DNQpL34WoaeK"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z4XnShbjoaeN"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "criterion_mae = torch.nn.L1Loss()\n",
    "criterion_rmse = RMSELoss()\n",
    "def report_regression_results(y_true, y_pred):\n",
    "    # Print multiple regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    adjusted_r2 =  1.0 - ( mse / y_true.var() )\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('Adjusted r2: ', round(adjusted_r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))\n",
    "    # save a plot with the residuals\n",
    "    plt.scatter(y_pred,(y_true - y_pred),edgecolors='black')\n",
    "    plt.title('Fitted vs. residuals plot')\n",
    "    plt.xlabel(\"Fitted\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.show()\n",
    "    f.savefig(\"report-experiment1.pdf\", bbox_inches='tight')\n",
    "    \n",
    "def report_explained_variance(y_true, y_pred):\n",
    "    batch, ch, lat, lon = y_true.shape\n",
    "    explained_variance = 0\n",
    "    for i in range(batch):\n",
    "        explained_variance += metrics.explained_variance_score(y_true[i,0,:,:], y_pred[i,0,:,:])\n",
    "    return explained_variance / (batch)\n",
    "\n",
    "def report_r2(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred) \n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    ar2 =  1.0 - ( mse / y_true.var() )\n",
    "    return r2, ar2\n",
    "\n",
    "def report_losses(y_true, y_pred):\n",
    "    mae = criterion_mae(y_true, y_pred)\n",
    "    rmse = criterion_rmse(y_true, y_pred)\n",
    "    return mae, rmse\n",
    "\n",
    "def report_metrics(y_true, y_pred, removed):\n",
    "    batch, ch, time, lat, lon = y_true.shape\n",
    "    r2 = 0.0\n",
    "    ar2 = 0.0\n",
    "    mae = 0.0\n",
    "    rmse = 0.0\n",
    "    for i in range(batch):\n",
    "        v1,v2 = report_r2(y_true[i,0,removed[i],:,:], y_pred[i,0,removed[i],:,:])\n",
    "        r2 += v1\n",
    "        ar2 += v2\n",
    "        v1, v2 = report_losses(y_true[i,0,removed[i],:,:], y_pred[i,0,removed[i],:,:])\n",
    "        mae += v1\n",
    "        rmse += v2\n",
    "    r2 = r2/(batch)\n",
    "    ar2 = ar2/(batch)\n",
    "    mae = mae/batch\n",
    "    rmse = rmse/batch\n",
    "    return mae, rmse, r2, ar2\n",
    "\n",
    "def plot_residual_fitted(y_true, y_pred):\n",
    "    plt.scatter(y_pred,(y_true - y_pred), alpha=0.5)\n",
    "    plt.title('STConvS2S')\n",
    "    plt.xlabel(\"Fitted\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSPtZj8pPlp5"
   },
   "outputs": [],
   "source": [
    "def init_hidden(batch_size, hidden_size, device):\n",
    "    h = torch.zeros(batch_size,hidden_size, device=device)\n",
    "    return (h,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYdlOlkLoaeQ"
   },
   "outputs": [],
   "source": [
    "model, optimizer, epoch, loss = trainer.load_model()\n",
    "batch_test_loss_mae = 0.0\n",
    "batch_test_loss_rmse = 0.0\n",
    "batch_explained_variance = 0.0\n",
    "batch_r2 = 0.0\n",
    "batch_ar2 = 0.0\n",
    "model.eval()\n",
    "y_true = None\n",
    "with torch.no_grad():\n",
    "    for i, (x, y, removed) in enumerate(test_loader):\n",
    "        x,y,removed = x.to(device), y.to(device), removed.to(device)\n",
    "        states_fwd = init_hidden(x.size()[0], x.size()[3]*x.size()[4], device)\n",
    "        states_bckwd = init_hidden(x.size()[0], x.size()[3]*x.size()[4], device)\n",
    "        output = model(x, states_fwd, states_bckwd, removed)\n",
    "        loss_mae, loss_rmse, r2, ar2 = report_metrics(y, output, removed)\n",
    "        if (i == 0):\n",
    "            plot_residual_fitted(y[0,0,removed[i],:,:].cpu(), output[0,0,removed[i],:,:].cpu())\n",
    "        batch_test_loss_mae += loss_mae.detach().item()\n",
    "        batch_test_loss_rmse += loss_rmse.detach().item()\n",
    "        batch_r2 += r2\n",
    "        batch_ar2 += ar2\n",
    "        \n",
    "test_loss_mae = batch_test_loss_mae/len(test_loader)\n",
    "test_loss_rmse = batch_test_loss_rmse/len(test_loader)\n",
    "explained_variance = batch_explained_variance/len(test_loader)\n",
    "r2 = batch_r2/len(test_loader)\n",
    "ar2 = batch_ar2/len(test_loader)\n",
    "print(f'MAE: {test_loss_mae:.4f}')\n",
    "print(f'RMSE: {test_loss_rmse:.4f}')\n",
    "print('Explained variance: ', round(explained_variance,4))\n",
    "print('r2: ', round(r2,4))\n",
    "print('ar2: ', round(ar2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GA-3z8pKyee7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ST-RFD-EvoNormB03D-Updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
